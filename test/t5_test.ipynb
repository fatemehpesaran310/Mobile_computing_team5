{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referenced: \n",
    "https://turbolab.in/abstractive-summarization-using-googles-t5/\n",
    "https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kims90/virtual_envs/mobile_prj/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kims90/virtual_envs/mobile_prj/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer_t5_large = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "model_t5_large = T5ForConditionalGeneration.from_pretrained(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/kims90/.cache/huggingface/datasets/kmfoda___csv/kmfoda--booksum-025141c210e07407/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 635.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"kmfoda/booksum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t5_large.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarization_t5(text_input):\n",
    "    text = text_input\n",
    "    text = text.replace('\\n','')\n",
    "    input_ids = tokenizer_t5_large.encode(\n",
    "        \"summarize: \" +  text, return_tensors=\"pt\", max_length = 512, truncation = True,  padding=True\n",
    "    ) # Batch size 1\n",
    "    input_ids = input_ids.to('cuda')\n",
    "    outputs = model_t5_large.generate(input_ids, num_beams=2, no_repeat_ngram_size=3, length_penalty=2.0, min_length=50, max_length=5000, early_stopping=True)\n",
    "    summary_txt = tokenizer_t5_large.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return summary_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../rouge_calc')\n",
    "\n",
    "import model_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1431/1431 [39:22<00:00,  1.65s/it]\n",
      "100%|██████████| 1431/1431 [00:11<00:00, 125.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "all_summ = []\n",
    "\n",
    "for i in tqdm(range(len(dataset[\"test\"]))):\n",
    "    summarized_output = text_summarization_t5(dataset[\"test\"][\"chapter\"][i])\n",
    "    all_summ.append(summarized_output)\n",
    "\n",
    "t5_large_rouge = model_rouge.calc_rouge_pred(all_summ, dataset[\"test\"][\"summary_text\"], rouge)\n",
    "model_rouge.print_txt(t5_large_rouge, '../rouge_calc/t5_large_rouge.txt')\n",
    "pickle.dump(t5_large_rouge, open('../rouge_calc/dict_pickle/t5_large_rouge.dict', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summarization_t5_param(text_input, num_beams_v, no_repeat_ngram_size_v, length_penalty_v, min_length_v, max_length_v, early_stopping_v):\n",
    "    text = text_input\n",
    "    text = text.replace('\\n','')\n",
    "    input_ids = tokenizer_t5_large.encode(\n",
    "        \"summarize: \" +  text, return_tensors=\"pt\", max_length = 512, truncation = True,  padding=True\n",
    "    ) # Batch size 1\n",
    "    input_ids = input_ids.to('cuda')\n",
    "    outputs = model_t5_large.generate(input_ids, num_beams=num_beams_v, no_repeat_ngram_size=no_repeat_ngram_size_v, length_penalty=length_penalty_v, min_length=min_length_v, max_length=max_length_v, early_stopping=early_stopping_v)\n",
    "    summary_txt = tokenizer_t5_large.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return summary_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1431/1431 [43:31<00:00,  1.83s/it]\n",
      "100%|██████████| 1431/1431 [00:12<00:00, 118.22it/s]\n"
     ]
    }
   ],
   "source": [
    "all_summ_v = []\n",
    "\n",
    "for i in tqdm(range(len(dataset[\"test\"]))):\n",
    "    summarized_output = text_summarization_t5_param(dataset[\"test\"][\"chapter\"][i], 4, 3, 2.0, 56, 142, True )\n",
    "    all_summ_v.append(summarized_output)\n",
    "\n",
    "t5_large_rouge_v = model_rouge.calc_rouge_pred(all_summ_v, dataset[\"test\"][\"summary_text\"], rouge)\n",
    "model_rouge.print_txt(t5_large_rouge_v, '../rouge_calc/t5_large_rouge_v.txt')\n",
    "pickle.dump(t5_large_rouge_v, open('../rouge_calc/dict_pickle/t5_large_rouge_v.dict', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summ_v = []\n",
    "\n",
    "for i in tqdm(range(len(dataset[\"test\"]))):\n",
    "    half_length = len(dataset[\"test\"][\"chapter\"][i])//2\n",
    "    summarized_output = text_summarization_t5_param(dataset[\"test\"][\"chapter\"][i], 4, 3, 2.0, 56, half_length, True )\n",
    "    all_summ_v.append(summarized_output)\n",
    "\n",
    "t5_large_rouge_v = model_rouge.calc_rouge_pred(all_summ_v, dataset[\"test\"][\"summary_text\"], rouge)\n",
    "model_rouge.print_txt(t5_large_rouge_v, '../rouge_calc/t5_large_rouge_v.txt')\n",
    "pickle.dump(t5_large_rouge_v, open('../rouge_calc/dict_pickle/t5_large_rouge_v.dict', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../source_text/pride_and_prejudice_ch1_part.txt\", \"r\")\n",
    "q_text = f.read()\n",
    "\n",
    "result = text_summarization_t5_param(q_text, 4, 3, 2.0, 56, 156, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a single man in possession of a good fortune, must be in want ofa wife. this truth is so well fixed in the minds of the surrounding families, that he is considered the rightfulproperty of some one orother of their daughters. \"my dear, my dear, do you not want to know who has taken it?” cried his wife impatiently.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'around £200m will be spent on food and drink this weekend, according to the centre for retail research. supermarket chain Lidl said it had sold enough bunting to line the Coronation procession route 75 times over. Tesco said it was on track to sell 675,000 pork pies and 300,000 pots of clotted cream.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"../source_text/bbc_news_part.txt\", \"r\")\n",
    "q_text = f.read()\n",
    "\n",
    "result = text_summarization_t5_param(q_text, 4, 3, 2.0, 56, 156, True)\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobile_prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
